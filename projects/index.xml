<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Arindam Ghosh / Computer Vision Researcher</title>
    <link>https://aryndam9.github.io/projects/</link>
    <description>Recent content in Projects on Arindam Ghosh / Computer Vision Researcher</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>© 2023 Arindam Ghosh</copyright>
    <lastBuildDate>Tue, 22 Dec 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://aryndam9.github.io/projects/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>IRIS Flight Software Development</title>
      <link>https://aryndam9.github.io/projects/iris-rover/</link>
      <pubDate>Tue, 22 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://aryndam9.github.io/projects/iris-rover/</guid>
      <description>Github
I helped develop the C&amp;amp;DH flight software for IRIS, CMU&amp;rsquo;s Lunar Rover. The flight software uses NASA JPL&amp;rsquo;s F-Prime flight-software framework on top of FreeRTOS. The C&amp;amp;DH is a TI Hercules Safety-Microcontroller.
Links: Github </description>
      <content>&lt;p&gt;&lt;a href=&#34;https://github.com/PlanetaryRobotics/CubeRoverPackage&#34;&gt;Github&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I helped develop the C&amp;amp;DH flight software for IRIS, CMU&amp;rsquo;s Lunar Rover.
The flight software uses NASA JPL&amp;rsquo;s F-Prime flight-software framework on top of FreeRTOS.
The C&amp;amp;DH is a TI Hercules Safety-Microcontroller.&lt;/p&gt;
&lt;h4 id=&#34;links&#34;&gt;Links:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/PlanetaryRobotics/CubeRoverPackage&#34;&gt;Github&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
    </item>
    
    <item>
      <title>Evaluation of ASR in Musical Environments</title>
      <link>https://aryndam9.github.io/projects/asr-music-semester-project/</link>
      <pubDate>Mon, 14 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://aryndam9.github.io/projects/asr-music-semester-project/</guid>
      <description>Github
ASR is used heavily in eyes-busy or hands-busy situations and often time the user may be speaking over noise. My peers and I are particularly interested in how music effects ASR decoding. We use several music datasets of varied genre or broken-down instrumentation to allow us to perform in-depth anaysis of how different aspects of music influences speech recognizer&amp;rsquo;s performance. We then train a new model from what we have learned to see if we could improve the original model&amp;rsquo;s performance.</description>
      <content>&lt;p&gt;&lt;a href=&#34;https://github.com/justinnuwin/Evaluation-of-ASR-in-Musical-Environment&#34;&gt;Github&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ASR is used heavily in eyes-busy or hands-busy situations and often time the user may be speaking over noise.
My peers and I are particularly interested in how music effects ASR decoding.
We use several music datasets of varied genre or broken-down instrumentation to allow us to perform in-depth anaysis of how different aspects of music influences speech recognizer&amp;rsquo;s performance.
We then train a new model from what we have learned to see if we could improve the original model&amp;rsquo;s performance.&lt;/p&gt;

  &lt;img src=&#34;https://aryndam9.github.io/projects/asr-music-semester-project/poster.png&#34;  alt=&#34;ASR Music Evaluation semester project poster&#34;  class=&#34;center&#34;  /&gt;


&lt;h4 id=&#34;links&#34;&gt;Links:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/justinnuwin/Evaluation-of-ASR-in-Musical-Environment/blob/master/18-781_Project_Report.pdf&#34;&gt;Paper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aryndam9.github.io/projects/asr-music-semester-project/poster.pdf&#34;&gt;Poster&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/justinnuwin/Evaluation-of-ASR-in-Musical-Environment&#34;&gt;Github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/justinnuwin/Evaluation-of-ASR-in-Musical-Environment#releases&#34;&gt;Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
    </item>
    
    <item>
      <title>Embedded LS-PIV for Measuring Stream Flows</title>
      <link>https://aryndam9.github.io/projects/lspiv-semester-project/</link>
      <pubDate>Sat, 12 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://aryndam9.github.io/projects/lspiv-semester-project/</guid>
      <description>Bitbucket not currently public
The USGS measures stream flows since they are critical for long-term tracking and modeling/forecasting to ensure that federal water priorities and responsibilities can be met and that the nation’s rivers canbe effectively managed. Recently, the USGS has been looking at non-contact methods of collection this data which would allow USGS scientists to gather data more safely and possibly without even going in to the field. One such method is large-scale particle image velocimetry (LS-PIV).</description>
      <content>&lt;p&gt;&lt;a href=&#34;#&#34;&gt;Bitbucket &lt;strong&gt;not currently public&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The USGS measures stream flows since they are critical for long-term tracking and modeling/forecasting to ensure that federal water priorities and responsibilities can be met and that the nation’s rivers canbe effectively managed.
Recently, the USGS has been looking at non-contact methods of collection this data which would allow USGS scientists to gather data more safely and possibly without even going in to the field.
One such method is large-scale particle image velocimetry (LS-PIV).
LS-PIV is a special case of algorithms that perform optical flow; at its is a cross correlation operation which is expensive in both time complexity and energy usage.
My peers and I optimize the PIV algorithm to run on a 32-bit embedded microcontroller that can quickly and accurately perform the PIV computation and have a battery life of up to 2 years.&lt;/p&gt;

  &lt;img src=&#34;https://aryndam9.github.io/projects/lspiv-semester-project/poster.png&#34;  alt=&#34;Embedded LS-PIV semester project poster&#34;  class=&#34;center&#34;  /&gt;


&lt;h4 id=&#34;links&#34;&gt;Links:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aryndam9.github.io/projects/lspiv-semester-project/paper.pdf&#34;&gt;Paper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aryndam9.github.io/projects/lspiv-semester-project/presentation.pdf&#34;&gt;Presentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aryndam9.github.io/projects/lspiv-semester-project/poster.pdf&#34;&gt;Poster&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#&#34;&gt;Bitbucket &lt;strong&gt;not currently public&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
    </item>
    
    <item>
      <title>Denoising EEG Signals</title>
      <link>https://aryndam9.github.io/projects/denoising-eeg-semester-project/</link>
      <pubDate>Tue, 08 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://aryndam9.github.io/projects/denoising-eeg-semester-project/</guid>
      <description>Github
EEGs are extremely interesting to the signal processing world as the signals from them are high dimensional and localized spatially, spectrally, and temporally. These signals are extremely low amplitude and artifacts appear in the measured signal due to normal human processes like blinking, breathing, and moving; or noise can appear due to the external factors such as line noise or sound in the room. My peers and I implement Viola&amp;rsquo;s ICA CorrMap procedure to denoise EEGs, but rather than retreiving EEG artifacts in-situ, we use Cho&amp;rsquo;s EEG dataset which separately records subjects in both rest states and performing various &amp;rsquo;noisy&amp;rsquo; actions prior to a motor imagery trial.</description>
      <content>&lt;p&gt;&lt;a href=&#34;https://github.com/justinnuwin/Denoising-EEG-Signals&#34;&gt;Github&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;EEGs are extremely interesting to the signal processing world as the signals from them are high dimensional and localized spatially, spectrally, and temporally.
These signals are extremely low amplitude and artifacts appear in the measured signal due to normal human processes like blinking, breathing, and moving; or noise can appear due to the external factors such as line noise or sound in the room.
My peers and I implement Viola&amp;rsquo;s ICA CorrMap procedure to denoise EEGs, but rather than retreiving EEG artifacts in-situ, we use Cho&amp;rsquo;s EEG dataset which separately records subjects in both rest states and performing various &amp;rsquo;noisy&amp;rsquo; actions prior to a motor imagery trial.
We use this data to try and denoise signals and try to devise a way to create a generalized artifact template that can be transferred from user to user.&lt;/p&gt;
&lt;h4 id=&#34;links&#34;&gt;Links:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/justinnuwin/Denoising-EEG-Signals/blob/master/18-797_Project_Report.pdf&#34;&gt;Paper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/justinnuwin/Denoising-EEG-Signals&#34;&gt;Github&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
    </item>
    
    <item>
      <title>potatOS</title>
      <link>https://aryndam9.github.io/projects/potatos/</link>
      <pubDate>Fri, 14 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://aryndam9.github.io/projects/potatos/</guid>
      <description>Github
I developed an x86_64 operating system and kernel from scratch. The OS has virtual memory and threading implemented.
Links: Github </description>
      <content>&lt;p&gt;&lt;a href=&#34;https://github.com/justinnuwin/potatos&#34;&gt;Github&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I developed an x86_64 operating system and kernel from scratch.
The OS has virtual memory and threading implemented.&lt;/p&gt;
&lt;h4 id=&#34;links&#34;&gt;Links:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/justinnuwin/potatos&#34;&gt;Github&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
    </item>
    
    <item>
      <title>Autonomous Navigation System for Mapping &amp; Traversing Rugged Terrain</title>
      <link>https://aryndam9.github.io/projects/cp-capstone/</link>
      <pubDate>Wed, 20 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://aryndam9.github.io/projects/cp-capstone/</guid>
      <description>Github
The Northrop Grumman Collaboration Project (NGCP) is a project-club at Cal Poly that participates in engineering challenges posed by Northrop Grumman. The collaboration project is with Northrop Grumman, in addition to Cal Poly Pomona with whom the work for the engineering challenge is split with. The 2019 school year had a new mission which was a rugged-terrain rescue mission. My peers and I were tasked with with sensing and intelligence for one of their new vehicles.</description>
      <content>&lt;p&gt;&lt;a href=&#34;https://github.com/justinnuwin/NGCP-Capstone-UGV&#34;&gt;Github&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The Northrop Grumman Collaboration Project (NGCP) is a project-club at Cal Poly that participates in engineering challenges posed by Northrop Grumman.
The collaboration project is with Northrop Grumman, in addition to Cal Poly Pomona with whom the work for the engineering challenge is split with.
The 2019 school year had a new mission which was a rugged-terrain rescue mission.
My peers and I were tasked with with sensing and intelligence for one of their new vehicles.&lt;/p&gt;

  &lt;img src=&#34;https://aryndam9.github.io/projects/cp-capstone/poster.png&#34;  alt=&#34;ASR Music Evaluation semester project poster&#34;  class=&#34;center&#34;  /&gt;


&lt;h4 id=&#34;links&#34;&gt;Links:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aryndam9.github.io/projects/cp-capstone/report.pdf&#34;&gt;Report&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aryndam9.github.io/projects/cp-capstone/poster.png&#34;&gt;Poster&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/justinnuwin/NGCP-Capstone-UGV&#34;&gt;Github&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
    </item>
    
  </channel>
</rss>
